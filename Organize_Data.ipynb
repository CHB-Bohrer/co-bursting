{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Code to organize data so that it can be processed in // Bohrer and Larson 2022 <\\h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are going to load in the needed programs, if you dont have them you will have to get them\n",
    "import numpy as np\n",
    "import pickle \n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import dill #This will be used to store the workplace so you dont have to run certain cells\n",
    "sns.set()\n",
    "import os \n",
    "from math import nan\n",
    "import math \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are going to link the individual chromosomes with their transcription states so it is easier to handle\n",
    "#This is what we mean by linked trajectories.\n",
    "\n",
    "\n",
    "try: \n",
    "    os.makedirs('Linked_Trajectories') \n",
    "except:\n",
    "    print('File is allready there Chris!')\n",
    "\n",
    "#Load in the data used, will be over 7000 chromosomes \n",
    "filename=\"chromosome21.tsv\"\n",
    "df_temp = pd.read_csv(filename,sep=\"\\t\")\n",
    "\n",
    "\n",
    "#Here is the actual code, very straight forward, this is for the dis\n",
    "ars=df_temp['Chromosome copy number'].to_numpy()\n",
    "xx=df_temp['X(nm)'].to_numpy()\n",
    "yy=df_temp['Y(nm)'].to_numpy()\n",
    "zz=df_temp['Z(nm)'].to_numpy()\n",
    "index=df_temp['Genomic coordinate'].to_numpy()\n",
    "\n",
    "Trans_state=df_temp['Transcription'].to_numpy()\n",
    "Check=np.unique(index)\n",
    "\n",
    "\n",
    "for kcat in np.unique(ars):\n",
    "    \n",
    "    Cords=np.zeros(len(Check))\n",
    "    inds=df_temp['Chromosome copy number']==kcat\n",
    "    \n",
    "    if len(index[inds])==len(Cords):\n",
    "        \n",
    "        Cords=np.transpose([xx[inds], yy[inds], zz[inds]])\n",
    "        \n",
    "        file = \"Linked_Trajectories/Test\"+str(kcat)\n",
    "        np.save(file, Cords)  \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('problem')\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#This is going to link together the corresponding transcription trajectories, it is also going to grab out the gene names\n",
    "#Note, if there are multiple genes per a locus, then we only take the first one so that we do not over weight that locus. \n",
    "        \n",
    "        \n",
    "#Make the directories if they are not there\n",
    "try: \n",
    "    os.makedirs('Transcription_Trajectories') \n",
    "except:\n",
    "    print('File is allready there Chris!')\n",
    "    \n",
    "try: \n",
    "    os.makedirs('Gene_Names') \n",
    "except:\n",
    "    print('File is allready there Chris!')\n",
    "\n",
    "\n",
    "ars=df_temp['Chromosome copy number'].to_numpy()\n",
    "xx=df_temp['X(nm)'].to_numpy()\n",
    "yy=df_temp['Y(nm)'].to_numpy()\n",
    "zz=df_temp['Z(nm)'].to_numpy()\n",
    "index=df_temp['Genomic coordinate'].to_numpy()\n",
    "\n",
    "Trans_state=df_temp['Transcription'].to_numpy()\n",
    "Check=np.unique(index)\n",
    "\n",
    "Gene_Names=df_temp['Gene names'].to_numpy()\n",
    "\n",
    "\n",
    "(_, _, filenames) = next(os.walk('Linked_Trajectories'))\n",
    "\n",
    "new_lined_up_ind=[]\n",
    "for kcat in range(len(filenames)):\n",
    "    filenames_2=filenames[kcat]\n",
    "    new_lined_up_ind.append(int(filenames_2[4:-4]))\n",
    "\n",
    "\n",
    "for i in range(len(Check)):\n",
    "    print(i)\n",
    "\n",
    "    Cords3=np.zeros(len(np.unique(ars)))\n",
    "    Gene_Names_to_Save=np.zeros(len(np.unique(ars)))\n",
    "    \n",
    "    count=0\n",
    "    for kcat in range(len(new_lined_up_ind)):\n",
    "        \n",
    "        \n",
    "        #Little different than before, but will line up correctly\n",
    "        inds=df_temp['Chromosome copy number']==kcat+1\n",
    "\n",
    "\n",
    "        Cords2=Trans_state[inds]\n",
    "        Gene_Names_Temp=Gene_Names[inds]\n",
    "        \n",
    "        try:\n",
    "            np.isnan(Cords2[i])\n",
    "            Cords3[count]=nan\n",
    "            Gene_Name_Temper=nan\n",
    "        except:\n",
    "            tempstate=Cords2[i]\n",
    "            Gene_Name_Temper=Gene_Names_Temp[i]\n",
    "\n",
    "            if tempstate[0:2]=='on':\n",
    "                Cords3[count]=1\n",
    "            elif tempstate[0:2]=='of':\n",
    "                Cords3[count]=0\n",
    "            else:\n",
    "                Cords3[count]=nan\n",
    "            \n",
    "        count=count+1\n",
    "\n",
    "   \n",
    "    file = \"Transcription_Trajectories/Test\"+str(i)\n",
    "    np.save(file, Cords3)\n",
    "    \n",
    "    file = \"Gene_Names/Test\"+str(i)\n",
    "    np.save(file, Gene_Name_Temper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Gathering Distances in individual files </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the code for generating the individual distance files. Aka for the distances from one locus to all others for different chromosomes. \n",
    "#The way this was set up was for on a cluster. It is easy to code this so if you want to run it, you might as well write your own version. \n",
    "#The results of this analysis are in the folder 'Distances'\n",
    "\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pickle \n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from math import nan\n",
    "import dill #This will be used to store the workplace so you dont have to run certain cells\n",
    "import NPEETmaster.npeet.entropy_estimators as ee\n",
    "sns.set()\n",
    "from scipy.stats import entropy\n",
    "from pathlib import Path\n",
    "from math import nan\n",
    "import signal\n",
    "\n",
    "\n",
    "\n",
    "def init_worker():\n",
    "    \"\"\"\n",
    "    This is necessary to be able to interrupt the\n",
    "    script with CTRL-C (or scancel for that matter).\n",
    "    It makes sure that the workers ignore SIGINT so\n",
    "    that any SIGINT sent goes to the master process\n",
    "    \"\"\"\n",
    "    signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "\n",
    "\n",
    "def worker(kcat):\n",
    "        print('Here we go',kcat)\n",
    "        \n",
    "        Data_Folder='/data/bohrerch/'\n",
    "        #Data_Folder=''\n",
    "        areol=np.random.randint(0,100)+kcat\n",
    "        np.random.seed(seed=areol)\n",
    "        \n",
    "        for ksksks in range(1000):\n",
    "            num_of_loci=500\n",
    "            (_, _, filenames) = next(os.walk(Data_Folder+'Linked_Trajectories'))\n",
    "            Cor=np.load(Data_Folder+'Linked_Trajectories/'+filenames[0])\n",
    "            num_of_loci=len(Cor)\n",
    "            barcode1=np.random.randint(0,num_of_loci)\n",
    "            \n",
    "            file = Path(Data_Folder+\"Distances/Distances_\"+str(barcode1))\n",
    "            print('Im inside')\n",
    "            \n",
    "            if file.is_file()==0:\n",
    "                df = pd.DataFrame();\n",
    "                for barcode2 in range(num_of_loci):\n",
    "                    df1 = pd.DataFrame();\n",
    "\n",
    "                    print(barcode1/num_of_loci, barcode2/num_of_loci, kcat)\n",
    "\n",
    "                    distances=[]\n",
    "                    count=0\n",
    "                    for kcat2 in range(len(filenames)):\n",
    "\n",
    "                        file = Data_Folder+\"Linked_Trajectories/Test\"+str(kcat2+1)+'.npy'\n",
    "                        Cor=np.load(file)\n",
    "\n",
    "                        dis=pdist(np.vstack((Cor[barcode1,:],Cor[barcode2,:])))\n",
    "                        newdis=dis[0]\n",
    "                        \n",
    "                        distances.append(newdis)\n",
    "                        \n",
    "\n",
    "                    df1[\"barcode\"+str(barcode2)]=np.abs(distances)\n",
    "                    df=pd.concat([df,df1], axis=1)\n",
    "\n",
    "                file = Data_Folder+\"Distances/Distances_\"+str(barcode1)\n",
    "\n",
    "                df.to_csv(file,index=False)\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nproc = int(os.environ.get(\"SLURM_CPUS_PER_TASK\", \"2\"))\n",
    "    print(\"Running on %d CPUs\" % nproc)\n",
    "    \n",
    "    p = Pool(nproc, init_worker)\n",
    "    try:\n",
    "                # the the number of allocated cpus (or 2 if not run as a slurm job)\n",
    "               \n",
    "\n",
    "               \n",
    "\n",
    "                num_of_loci=1600\n",
    "\n",
    "\n",
    "                tasks = range(0, 100)\n",
    "                print('Hey Im starting')                    # Create a multiprocessing Pool\n",
    "                p.map(worker, tasks) \n",
    "\n",
    "\n",
    "\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "            p.close()\n",
    "            p.join()\n",
    "            # result summary\n",
    "            #print(\"\\n\".join(\"%d * %d = %d\" % (a, a, b) for a, b in zip(tasks, results)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
